#version 460
#extension GL_ARB_separate_shader_objects : enable
#extension GL_GOOGLE_include_directive : enable

#include "../include/common.glsl"







// #define ENABLE_RAY_TRACING true					

// float query(vec3 pos, vec3 dir, float tmin, float tmax)
// {
//     if(ENABLE_RAY_TRACING)
//     {
//         rayQueryEXT query;
//         rayQueryInitializeEXT(
//             query, 
//             TLAS, 
//             gl_RayFlagsTerminateOnFirstHitEXT, 
//             0xFF, 
//             pos, 
//             tmin, 
//             dir, 
//             tmax);

//         rayQueryProceedEXT(query);
//         float dist = tmax;
//         if (rayQueryGetIntersectionTypeEXT(query, true) != gl_RayQueryCommittedIntersectionNoneEXT)
//         {
//             dist = rayQueryGetIntersectionTEXT(query, true);
//         }

//         return dist;
//     }
//     else return tmax;
// }


layout(push_constant) uniform sSSRSetting {
    int max_mip;
    int start_mip;
    int end_mip;
	float thickness;
    int max_loop;
    float scale;
    float max_roughness;
    float importance_sample_bias;
    float min_hit_distance;

    bool enable_skybox;
    float blend;
    float filter_blend;
    float screen_fade;

} SSSRSetting;

 layout(set = 1, binding = 0)            uniform sampler2D STORAGE_IMAGE_SSSR_RAW;	    //换成sampler2D
 layout(set = 1, binding = 1)            uniform sampler2D STORAGE_IMAGE_SSSR_PDF;	
// layout(set = 1, binding = 0, rgba16f)   uniform image2D STORAGE_IMAGE_SSSR_RAW;	
// layout(set = 1, binding = 1, rgba16f)   uniform image2D STORAGE_IMAGE_SSSR_PDF;	
layout(set = 1, binding = 2, rgba16f)   uniform image2D STORAGE_IMAGE_SSSR_RESOLVE;	
layout(set = 1, binding = 3, rgba16f)   uniform image2D STORAGE_IMAGE_SSSR;		
layout(set = 1, binding = 4, rgba16f)   uniform image2D STORAGE_IMAGE_SSSR_HISTORY;			
layout(set = 1, binding = 5)            uniform sampler2D STORAGE_IMAGE_COLOR_PYRAMID;	


#define THREADS_X 32
#define THREADS_Y 32
#define THREADS_Z 1


float SSR_BRDF(vec3 V, vec3 L, vec3 N, float roughness)
{
    float a2 			= Pow4(roughness) ;      
	vec3 H = normalize(L + V);

	float NoH = max(dot(N, H), 0);
	float NoL = max(dot(N, L), 0);
	float NoV = max(dot(N, V), 0);

	float D = D_GGX(NoH, roughness);
	float G = Vis_Smith(a2, NoV, NoL ); 

	return max(0, D * G);
}

layout (local_size_x = THREADS_X, local_size_y = THREADS_Y, local_size_z = THREADS_Z) in;
void main() {

	ivec2 gID = ivec2(gl_GlobalInvocationID.xy);

    vec2 extent = HALF_SIZE_SSSR ? 
                    vec2(HALF_WINDOW_WIDTH, HALF_WINDOW_HEIGHT) : 
                    vec2(WINDOW_WIDTH, WINDOW_HEIGHT);

	if(gID.x >= extent.x || gID.y >= extent.y ) return;
	vec2 inUV = gID / extent;


	// 采样G Buffer信息 ////////////////////////////////////////////////////////////////////////////////////

    //
    float depth             = fetchDepth(inUV);
    if(depth == 1)
    {
        imageStore(STORAGE_IMAGE_SSSR_RESOLVE, ivec2(gID.xy), vec4(0.0f) );
        return;
    }

    //vec4 worldPos    		= depthToWorld(inUV);        	
    vec4 worldPos    		= screenToWorld(inUV, depth);
 
    vec3 N              = fetchNormal(inUV);    
    vec3 V              = normalize(CAMERA.pos.xyz - worldPos.xyz);	
    vec3 R              = normalize(reflect(-V, N));     //反射

    float metallic      = fetchMetallic(inUV);
    float roughness     = fetchRoughness(inUV);
    float a2            = Pow4(roughness);
    vec4 albedo         = fetchDiffuse(inUV);       //TODO所有的信息都从G-Buffer里取得，后续渲染被前向的挡住了咋办？

    vec3 F0             = vec3(0.04f);  
    F0                  = mix(F0, albedo.rgb, metallic); 

    float NoV           = Saturate(dot(N, -V));
    float coneTangent   = Lerp(0, roughness * (1 - SSSRSetting.importance_sample_bias), NoV * sqrt(roughness)); //锥体追踪，没搞明白，暂时抄的

	// 本帧结果////////////////////////////////////////////////////////////////////////////////////

    vec2 noise = fetchNoise2D(gID) * 2 - 1;
    mat2 ditterRotation = mat2(noise.x, noise.y, -noise.x, -noise.y);

    vec4 accumulatedColor = vec4(0.0f);
    float weightSum = 0.0f;


    //TODO 根据粗糙度选择采样数目
    // ivec2 deltaUV[21] = {ivec2(0, 0), 
    //                     ivec2(-1, 0), ivec2(1, 0), ivec2(0, 1), ivec2(0, -1),
    //                     ivec2(-1, -1), ivec2(1, -1), ivec2(-1, 1), ivec2(1, 1),
    //                     ivec2(-2, -1), ivec2(-2, 0), ivec2(-2, 1), ivec2(2, -1),ivec2(2, 0), ivec2(2, 1), 
    //                     ivec2(-1, -2), ivec2(0, -2), ivec2(1, -2), ivec2(-1, 2), ivec2(0, 2), ivec2(1, 2)}; 

    ivec2 deltaUV[9] =  {   ivec2(-2.0, -2.0), ivec2(0.0, -2.0), ivec2(2.0, -2.0), 
                            ivec2(-2.0, 0.0), ivec2(0.0, 0.0), ivec2(2.0, 0.0), 
                            ivec2(-2.0, 2.0), ivec2(0.0, 2.0), ivec2(2.0, 2.0)};
    for(int i = 0; i < 9; i++)
    { 
        vec2 neighburUV     = inUV + ditterRotation * deltaUV[i] / extent;
        vec4 tarceResult    = texture(STORAGE_IMAGE_SSSR_RAW, neighburUV);
        float hitPdf        = texture(STORAGE_IMAGE_SSSR_PDF, neighburUV).x;

        // ivec2 neighburTex   = gID.xy + ivec2(round(ditterRotation * deltaUV[i]));
        // //ivec2 neighburTex   = gID.xy + deltaUV[i];
        // vec4 tarceResult    = imageLoad(STORAGE_IMAGE_SSSR_RAW, neighburTex);
        // float hitPdf        = imageLoad(STORAGE_IMAGE_SSSR_PDF, neighburTex).x;
        float hitMask       = tarceResult.w;
        vec2 hitUV          = tarceResult.xy;   //tarceResult.z != fetchDepth

        vec4 hitPos         = depthToWorld(hitUV);
        vec3 L              = normalize(hitPos.xyz - worldPos.xyz);

        float weight         = SSR_BRDF(V, normalize(L), N, roughness) / max(1e-5, hitPdf);

        // 采样使用伪cone tracing，预先滤波颜色缓冲，然后根据粗糙度，追踪距离等估计采样mip
        float intersectionRadius = coneTangent * length(hitUV - inUV);
        float mip = clamp(log2(intersectionRadius * WINDOW_WIDTH), 0, 6);
        vec4 hitColor       = texture(STORAGE_IMAGE_COLOR_PYRAMID, hitUV, mip);   
        //vec4 hitColor       = texture(COLOR_0_SAMPLER, hitUV, 0);     
  

        accumulatedColor    += vec4(ToneMap(hitColor.rgb), hitMask) * weight; 
        weightSum           += weight;
    }
    accumulatedColor        = accumulatedColor / weightSum;
    accumulatedColor        = max(vec4(InverseToneMap(accumulatedColor.xyz), accumulatedColor.w), vec4(0.0f));
    
  


    //过程和镜面反射IBL完全一致，用半球radiance采样加权（在SSR里使用射线寻找，cone tracing也是类似的），乘以预积分部分
    vec3 kS = FresnelSchlickRoughness(NoV, F0, roughness); 
    vec3 kD = 1.0 - kS;

    vec2 brdf = texture(BRDF_LUT_SAMPLER, vec2(NoV, roughness)).rg;
    brdf = pow(brdf, vec2(1.0/2.2));      //gamma矫正

    vec3 reflection = accumulatedColor.xyz * accumulatedColor.w;               
    if(SSSRSetting.enable_skybox) reflection += PreFilteredReflection(R, roughness, SPECULAR_IBL_SAMPLER).rgb * (1 - accumulatedColor.w);	//没有trace到的就按天空盒处理？没有做可见性测试，会漏光


    vec3 specularColor = reflection * (kS * brdf.x + brdf.y);

    vec4 currentColor     = vec4(specularColor, 1.0f); 



	// 输出结果////////////////////////////////////////////////////////////////////////////////////

    imageStore(STORAGE_IMAGE_SSSR_RESOLVE, ivec2(gID.xy), currentColor );
}
